{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U02DenM0L0iv",
    "outputId": "0b130b07-fbda-4ec2-819d-da108f41b008"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "import yt_dlp\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Function to download video using yt-dlp\n",
    "def download_video(url, output_filename):\n",
    "    ydl_opts = {\n",
    "        'outtmpl': output_filename,\n",
    "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]'\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "\n",
    "# Function to extract keyframes\n",
    "def extract_keyframes(video_path, confidence=0.5, target_size=(480, 360)):\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Cannot open {video_path}\")\n",
    "        return []\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open {video_path}\")\n",
    "        return []\n",
    "\n",
    "    frames = []\n",
    "    prev_frame = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_resized = cv2.resize(frame, target_size)\n",
    "\n",
    "        if prev_frame is None:\n",
    "            frames.append(frame_resized)\n",
    "        else:\n",
    "            diff = cv2.absdiff(cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY),\n",
    "                               cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY))\n",
    "            score = np.mean(diff)\n",
    "\n",
    "            if score > (confidence * 255):\n",
    "                frames.append(frame_resized)\n",
    "\n",
    "        prev_frame = frame_resized\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {len(frames)} keyframes from {video_path}\")\n",
    "    return frames\n",
    "\n",
    "# Function to display extracted frames\n",
    "def display_frames(frames, title=\"Extracted Keyframes\"):\n",
    "    if not frames:\n",
    "        print(\"No frames to display.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(1, min(5, len(frames)), figsize=(15, 5))\n",
    "    if len(frames) == 1:\n",
    "        axes = [axes]  # Ensure axes is iterable when only one frame is present\n",
    "\n",
    "    for ax, frame in zip(axes, frames[:5]):  # Display up to 5 keyframes\n",
    "        ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Function to save summary video\n",
    "def save_summary_video(frames, output_filename, fps=10):\n",
    "    if not frames:\n",
    "        print(\"No frames to save.\")\n",
    "        return\n",
    "\n",
    "    writer = imageio.get_writer(output_filename, fps=fps)\n",
    "\n",
    "    for frame in frames:\n",
    "        writer.append_data(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    writer.close()\n",
    "    print(f\"Summary video saved: {output_filename}\")\n",
    "\n",
    "# Download two videos\n",
    "download_video(\"https://www.youtube.com/watch?v=ocPxX7NrcZQ\", \"video1.mp4\")\n",
    "download_video(\"https://www.youtube.com/watch?v=XZ5bGEhTKMg\", \"video2.mp4\")\n",
    "\n",
    "# Extract keyframes from both videos\n",
    "frames_video1 = extract_keyframes(\"video1.mp4\", confidence=0.5)\n",
    "frames_video2 = extract_keyframes(\"video2.mp4\", confidence=0.5)\n",
    "\n",
    "# Display extracted keyframes\n",
    "display_frames(frames_video1, title=\"Keyframes from Video 1\")\n",
    "display_frames(frames_video2, title=\"Keyframes from Video 2\")\n",
    "\n",
    "# Merge keyframes from both videos\n",
    "summary_frames = frames_video1 + frames_video2\n",
    "\n",
    "# Display summary frames\n",
    "display_frames(summary_frames, title=\"Summary Keyframes\")\n",
    "\n",
    "# Save summary video\n",
    "save_summary_video(summary_frames, \"summary.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOqQkHF1QOs8",
    "outputId": "85402ab1-1d33-475e-f50d-21fa4e02c558"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load YOLO model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Function to apply YOLO and extract features\n",
    "def detect_objects(frames):\n",
    "    feature_data = []\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        results = model(frame)\n",
    "        detected_objects = results.pandas().xyxy[0]['name'].tolist()\n",
    "\n",
    "        # Convert object list to numerical features\n",
    "        object_counts = {obj: detected_objects.count(obj) for obj in set(detected_objects)}\n",
    "        feature_vector = [\n",
    "            object_counts.get('person', 0),\n",
    "            object_counts.get('knife', 0),\n",
    "            object_counts.get('gun', 0),\n",
    "            object_counts.get('cell phone', 0),\n",
    "            object_counts.get('backpack', 0)\n",
    "        ]\n",
    "        feature_data.append(feature_vector)\n",
    "\n",
    "    return feature_data\n",
    "\n",
    "# Extract features from keyframes\n",
    "features = detect_objects(summary_frames)\n",
    "\n",
    "# Load or train a decision tree classifier\n",
    "try:\n",
    "    classifier = joblib.load(\"crime_classifier.pkl\")\n",
    "except FileNotFoundError:\n",
    "    X_train = np.random.randint(0, 5, (50, 5))  # Simulated training data\n",
    "    y_train = np.random.choice([0, 1], size=50)  # 0: No crime, 1: Crime detected\n",
    "    classifier = DecisionTreeClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    joblib.dump(classifier, \"crime_classifier.pkl\")\n",
    "\n",
    "# Predict crime occurrence\n",
    "predictions = classifier.predict(features)\n",
    "crime_detected = np.mean(predictions) > 0.5  # Decision based on majority\n",
    "\n",
    "print(\"Crime detected: shooting\" if crime_detected else \"No crime detected.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
